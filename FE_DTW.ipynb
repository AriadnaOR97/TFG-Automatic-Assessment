{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FE-DTW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AriadnaOR97/TFG-Automatic-Assessment/blob/master/FE_DTW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQys86vaYTMw",
        "colab_type": "text"
      },
      "source": [
        "# INTRODUCTION\n",
        "\n",
        "---\n",
        "\n",
        "This first part imports and installs all necessary libraries.\n",
        "\n",
        "NOTE: The proces od DTW takes 4419 cells/s, so it comparing 81*69 -> it takes 81*69/4419 s ~= 1,85 s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5n1ES59ZW4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic tools\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from numpy import argmax, mean, diff, log\n",
        "from matplotlib.mlab import find\n",
        "\n",
        "# Feature extraction\n",
        "import librosa \n",
        "!pip install soundfile\n",
        "import soundfile as sf\n",
        "\n",
        "# Data adquisition\n",
        "import pandas as pd\n",
        "\n",
        "# Learning\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix  \n",
        "\n",
        "print(\"\\nsoundfile installed. Necessary libraries imported.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3xStIQzedq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "#This will prompt the authentification\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# To acces to the directory\n",
        "!ls '/content/drive/My Drive/TFG - Ariadna'\n",
        "myDrive = '/content/drive/My Drive/TFG - Ariadna'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrT4FuJedScb",
        "colab_type": "text"
      },
      "source": [
        "# DTW\n",
        "\n",
        "---\n",
        "\n",
        "Here is initialized de Dynamic Time Warping Distance by 1-D and N-D. For mor detailed information click [here](https://en.wikipedia.org/wiki/Dynamic_time_warping)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMRayrrcQDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dtwDistance1D (array_1, array_2, detail_value):\n",
        "\n",
        "    # initialize all cost to infinity in DTW matrix NxMx1\n",
        "    DTW = np.zeros([len(array_1), len(array_2)]) + 1000\n",
        "\n",
        "    # set first element to 0.\n",
        "    DTW[0][0] = 0\n",
        "\n",
        "    for i in np.arange(1, len(array_1)):\n",
        "        for j in np.arange(1, len(array_2)):\n",
        "            cost = np.abs(array_1[i] - array_2[j])  # AQU√ç COMPTAR PESOS A 1\n",
        "            DTW[i][j] = cost + np.amin([DTW[i - 1][j], DTW[i][j - 1], DTW[i - 1][j - 1]])\n",
        "    if detail_value:  # if detail value is true, return all matrix\n",
        "        return DTW\n",
        "    else:\n",
        "        return DTW[len(array_1) - 1][len(array_2) - 1]\n",
        "\n",
        "      \n",
        "def dtwDistanceND(matrix_1, matrix_2, num_features, info):\n",
        "    start = time.process_time()\n",
        "    if info: print(\"Executing DTW...\")\n",
        "    # initialize all cost to infinity in DTW matrix NxMxF\n",
        "    DTW = np.zeros([num_features, len(matrix_1[0]), len(matrix_2[0])]) + 1000\n",
        "\n",
        "    # initialize cost array, considered as Indpendent\n",
        "    feature_cost = np.zeros(num_features)\n",
        "\n",
        "    for f in np.arange(0, num_features):\n",
        "        cost = dtwDistance1D(matrix_1[f], matrix_2[f], False)\n",
        "\n",
        "        # save all the costs\n",
        "        feature_cost[f] = float(cost)\n",
        "        #feature_cost[f] = DTW[f][len(matrix_1[0]) - 1][len(matrix_2[0]) - 1]\n",
        "\n",
        "    elapsed = time.process_time() - start\n",
        "    if info: print(\"Execution time: \" + str(elapsed) + \" s\\n\")\n",
        "    return feature_cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK7As_P2ly9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"print('---------------------- TEST 1 ----------------------')\n",
        "print('Testing multi-dimensional DTW Independent')\n",
        "m1 = [[1, 2, 3, 4, 5], [1, 2, 3, 5, 5]]\n",
        "m2 = [[1, 9, 8, 3, 4, 4, 5], [1, 2, 2, 3, 4, 5, 5]]\n",
        "num_features = 2\n",
        "\n",
        "m1_m2 = dtwDistanceND(m1, m2, num_features, info=True)\n",
        "print('Distance between m1 and m2: ' + str(m1_m2))\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKSTWOYyR56t",
        "colab_type": "text"
      },
      "source": [
        "# Median Filter\n",
        "---\n",
        "Median filter is used to filter the noise and also reduce the data in feature extraction process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSts7U9F3MoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def median(x):\n",
        "    x = np.abs(x)\n",
        "    x.sort()\n",
        "    median = x[int(np.floor(len(x)/2)-1)]\n",
        "    \n",
        "    return median\n",
        "\n",
        "  \n",
        "def medianFilter(x, hop_size):\n",
        "    if hop_size == 1:\n",
        "        return x\n",
        "      \n",
        "    new_x = []\n",
        "    i = 0\n",
        "    while i < len(x):\n",
        "        idx_end = i+hop_size\n",
        "        if idx_end < len(x):\n",
        "            new_x.append(median(x[i:idx_end -1]))\n",
        "        elif idx_end > len(x):\n",
        "            new_x.append(median(x[i:idx_end -1]))\n",
        "        i = i+hop_size\n",
        "        \n",
        "    return new_x\n",
        "  \n",
        "print(\"Median filter is initialized\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59ij-4RXEzcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"print('---------------------- TEST 2 ----------------------')\n",
        "x = [1,2,3,2,3,1,2,3,4,5,6,7,6,7,5,6,7]\n",
        "plt.plot(x)\n",
        "plt.plot(medianFilter(x,3))\n",
        "print(medianFilter(x,3))\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIGjegj513uM",
        "colab_type": "text"
      },
      "source": [
        "# Pitch Detecion\n",
        "---\n",
        "First feature extracted, based on zero crossing. This function is from [github](https://gist.github.com/endolith/255291)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t28ql8jPrPNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def freq_from_crossings(sig, fs):\n",
        "    # Find all indices right before a rising-edge zero crossing\n",
        "    indices = find((sig[1:] >= 0) & (sig[:-1] < 0))\n",
        "\n",
        "    # Naive (Measures 1000.185 Hz for 1000 Hz, for instance)\n",
        "    # crossings = indices\n",
        "\n",
        "    # More accurate, using linear interpolation to find intersample\n",
        "    # zero-crossings (Measures 1000.000129 Hz for 1000 Hz, for instance)\n",
        "    crossings = [i - sig[i] / (sig[i+1] - sig[i]) for i in indices]\n",
        "\n",
        "    # Some other interpolation based on neighboring points might be better.\n",
        "    # Spline, cubic, whatever\n",
        "\n",
        "    return fs / mean(diff(crossings))\n",
        "      \n",
        "def pitch_detection(y, sr, n_fft, hop_length):\n",
        "    voiceVector = []\n",
        "\n",
        "    window_position = 0\n",
        "    while window_position < len(y):\n",
        "      \n",
        "        idx_end = window_position+n_fft\n",
        "        if idx_end < len(y):\n",
        "            voiceVector.append(freq_from_crossings(y[window_position:idx_end -1],sr))\n",
        "            \n",
        "        elif idx_end > len(y):\n",
        "            voiceVector.append(freq_from_crossings(y[window_position:idx_end-1],sr))\n",
        "            \n",
        "        window_position = window_position+n_fft-hop_length\n",
        "    return voiceVector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woJztIqW2YDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"print('---------------------- TEST 3 ----------------------')\n",
        "y, sr = sf.read(myDrive + 'A3-A2.wav', dtype='float32')\n",
        "\n",
        "pitch = pitch_detection(y, sr, n_fft=1*1024, hop_length=512)\n",
        "print(len(pitch))\n",
        "centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "flatness = librosa.feature.spectral_flatness(y=y)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=1*1024, hop_length=512)\n",
        "zero_crossing = librosa.feature.spectral.zero_crossing_rate(y=y, frame_length = 1*1024, hop_length=512)\n",
        "mel_spectrum = librosa.feature.mfcc(y=y, sr=sr, n_fft=1*1024, n_mfcc=15) #Get 20 melspectrum\n",
        "\n",
        "      \n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nx-S8uRd8ob",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction\n",
        "\n",
        "---\n",
        "\n",
        "This is the first block of the all method. It extracts 20 features including pitch, spectral centroid, spectral flatness, spectral rollof, zero-crossing rate and MFCC. \n",
        "\n",
        "At the end of the process, it saves the data extracted into csv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIoUMyPWdNNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def featureExtraction(filenames, hop_size = 1):\n",
        "    # Get the file path to the included audio example\n",
        "    audio_features = []\n",
        "    start = time.process_time()\n",
        "    for filename in filenames:\n",
        "        # Load the audio as a waveform `y`\n",
        "        # Store the sampling rate as `sr`\n",
        "        # librosa needs to use float type for data\n",
        "        y, sr = sf.read(myDrive + '/SoundFiles/Exercise 14 - Segmented/' + filename, dtype='float32')\n",
        "\n",
        "        # Declare FFT properties\n",
        "        n_fft = 1024\n",
        "        hop_length = 512\n",
        "        \n",
        "        # Get features\n",
        "        pitch = pitch_detection(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
        "        centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        flatness = librosa.feature.spectral_flatness(y=y)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft = n_fft, hop_length=hop_length)\n",
        "        zero_crossing = librosa.feature.spectral.zero_crossing_rate(y=y, frame_length = n_fft, hop_length=hop_length)\n",
        "        mel_spectrum = librosa.feature.mfcc(y=y, sr=sr, n_fft=n_fft, n_mfcc=15) #Get 15 melspectrum\n",
        "        \n",
        "        # Apply medianfilter\n",
        "        pitch = medianFilter(pitch, hop_size)\n",
        "        centroid = medianFilter(centroid[0], hop_size)\n",
        "        flatness = medianFilter(flatness[0], hop_size)\n",
        "        rolloff = medianFilter(rolloff[0], hop_size)\n",
        "        zero_crossing = medianFilter(zero_crossing[0], hop_size)\n",
        "        MFCC_1 = medianFilter(mel_spectrum[0], hop_size)\n",
        "        MFCC_2 = medianFilter(mel_spectrum[1], hop_size)\n",
        "        MFCC_3 = medianFilter(mel_spectrum[2], hop_size)\n",
        "        MFCC_4 = medianFilter(mel_spectrum[3], hop_size)\n",
        "        MFCC_5 = medianFilter(mel_spectrum[4], hop_size)\n",
        "        MFCC_6 = medianFilter(mel_spectrum[5], hop_size)\n",
        "        MFCC_7 = medianFilter(mel_spectrum[6], hop_size)\n",
        "        MFCC_8 = medianFilter(mel_spectrum[7], hop_size)\n",
        "        MFCC_9 = medianFilter(mel_spectrum[8], hop_size)\n",
        "        MFCC_10 = medianFilter(mel_spectrum[9], hop_size)\n",
        "        MFCC_11 = medianFilter(mel_spectrum[10], hop_size)\n",
        "        MFCC_12 = medianFilter(mel_spectrum[11], hop_size)\n",
        "        MFCC_13 = medianFilter(mel_spectrum[12], hop_size)\n",
        "        MFCC_14 = medianFilter(mel_spectrum[13], hop_size)\n",
        "        MFCC_15 = medianFilter(mel_spectrum[14], hop_size)\n",
        "        \n",
        "        # Build matrix\n",
        "        M = pitch, centroid, flatness, rolloff, zero_crossing, MFCC_1, MFCC_2, MFCC_3,MFCC_4,MFCC_5,MFCC_6, MFCC_7, MFCC_8, MFCC_9, MFCC_10, MFCC_11, MFCC_12, MFCC_13, MFCC_14, MFCC_15\n",
        "\n",
        "        audio_features.append(M)\n",
        "        \n",
        "        \n",
        "    elapsed = time.process_time() - start\n",
        "    print(\"Features extracted from all data\")\n",
        "    print(\"Total number of audio analyzed: \" + str(len(audio_features)))\n",
        "    print(\"Total number of features extracted: \" + str(np.size(audio_features[0], axis=0)))\n",
        "    print(\"Execution time: \" + str(elapsed) + \" s\\n\")\n",
        "\n",
        "    return audio_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSoW3NCkeWV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Starting train\")\n",
        "# filenames ordered by level\n",
        "\n",
        "\"\"\" -------------------------- FULL AUDIO ----------------------------------- \"\"\"\n",
        "# Exercise 9 Pizzicato --------------------> DONE!!\n",
        "# filenames = \"0031.wav\", \"0051.wav\", \"0001.wav\", \"0011.wav\",  \"0061.wav\", \"0071.wav\"\n",
        "\n",
        "# Exercise 14 Kreutzer 4 --------------------> DONE!!\n",
        "# filenames = \"0032.wav\", \"0052.wav\", \"0002.wav\", \"0012.wav\",  \"0062.wav\", \"0072.wav\"\n",
        "\n",
        "# Exercise 18 Schradieck 1,1 --------------------> DONE!!\n",
        "# filenames = \"0033.wav\", \"0053.wav\", \"0003.wav\", \"0013.wav\",  \"0063.wav\", \"0073.wav\"\n",
        "\n",
        "# Exercise 20 Sevcik 16 --------------------> ERROR!!\n",
        "# filenames = \"0034.wav\", \"0054.wav\", \"0004.wav\", \"0014.wav\",  \"0064.wav\", \"0074.wav\"\n",
        "\n",
        "# Exercise 21 Shift 1st position --------------------> ERROR!!\n",
        "# filenames = \"0035.wav\", \"0055.wav\", \"0005.wav\", \"0015.wav\",  \"0065.wav\", \"0075.wav\"\n",
        "\n",
        "# Exercise 23 Shift 5th position --------------------> ERROR!!\n",
        "# filenames = \"0036.wav\", \"0056.wav\", \"0006.wav\", \"0016.wav\",  \"0066.wav\", \"0076.wav\"\n",
        "\n",
        "# Exercise 28 Flesch Arpeggio Excerpt --------------------> DONE!!\n",
        "# filenames = \"0037.wav\", \"0057.wav\", \"0007.wav\", \"0017.wav\",  \"0067.wav\", \"0077.wav\"\n",
        "\n",
        "# Exercise 30 G Major scale --------------------> DONE!!\n",
        "# filenames = \"0038.wav\", \"0058.wav\", \"0008.wav\", \"0018.wav\",  \"0068.wav\", \"0078.wav\"\n",
        "\n",
        "# Exercise 35 D Major scale --------------------> DONE!!\n",
        "# filenames = \"0039.wav\", \"0059.wav\", \"0009.wav\", \"0019.wav\",  \"0069.wav\", \"0079.wav\"\n",
        "\n",
        "# Exercise 38 Chromatic Scale --------------------> DONE!!\n",
        "# filenames = \"0040.wav\", \"0060.wav\", \"0010.wav\", \"0020.wav\",  \"0070.wav\", \"0080.wav\"\n",
        "\n",
        "\"\"\" ------------------------ SEGMENTED AUDIO -------------------------------- \"\"\"\n",
        "# Exercise 14 - P1\n",
        "# filenames = \"0032_p1.wav\", \"0052_p1.wav\", \"0002_p1.wav\", \"0012_p1.wav\",  \"0062_p1.wav\", \"0072_p1.wav\"\n",
        "\n",
        "# Exercise 14 - P2\n",
        "# filenames = \"0032_p2.wav\", \"0052_p2.wav\", \"0002_p2.wav\", \"0012_p2.wav\",  \"0062_p2.wav\", \"0072_p2.wav\"\n",
        "\n",
        "# Exercise 14 - P3\n",
        "# filenames = \"0032_p3.wav\", \"0052_p3.wav\", \"0002_p3.wav\", \"0012_p3.wav\",  \"0062_p3.wav\", \"0072_p3.wav\"\n",
        "\n",
        "# Exercise 14 - P4\n",
        "filenames = \"0032_p4.wav\", \"0052_p4.wav\", \"0002_p4.wav\", \"0012_p4.wav\",  \"0062_p4.wav\", \"0072_p4.wav\"\n",
        "\n",
        "labels = \"E\", \"E\", \"M\", \"M\", \"L\", \"L\"\n",
        "\n",
        "print(\"Extracting features...\")\n",
        "audio_features = featureExtraction(filenames, hop_size = 10)\n",
        "\n",
        "for i in np.arange(0, len(audio_features)):\n",
        "    print(\"   Length of features from \" + filenames[i] + \": \" + str(len(audio_features[i][1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEM6Jlj9Xsl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export features of each audio\n",
        "\n",
        "import csv\n",
        "\n",
        "for j in np.arange(0,len(filenames)):\n",
        "    \n",
        "    csv_filename = myDrive + '/Features extracted/' + filenames[j] + '.csv'\n",
        "    features_extracted = [\"pitch\",\"centroid\", \"flatness\", \"rolloff\", \"zero-crossing\", \"mel_01\", \"mel_02\", \"mel_03\", \"mel_04\", \"mel_05\", \"mel_06\", \"mel_07\", \"mel_08\", \"mel_09\", \"mel_10\", \"mel_11\", \"mel_12\", \"mel_13\", \"mel_14\", \"mel_15\"]\n",
        "    \n",
        "    with open(csv_filename, 'w') as csvfile:\n",
        "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "        #spamwriter.writerow(features_extracted)\n",
        "        for i in np.arange(0,len(features_extracted)):\n",
        "            spamwriter.writerow(audio_features[j][i])\n",
        "\n",
        "    print(\"Features are saved in \" + csv_filename)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiCQwNmIg5cN",
        "colab_type": "code",
        "outputId": "02e2e92f-37a3-4896-e3e7-aaff5448b705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# to know the total time of execution of DTW\n",
        "\n",
        "aver = 4419 #cells per second\n",
        "indi_time_exec = []\n",
        "\n",
        "matrix = len(audio_features[0][1])*len(audio_features[1][1])/aver\n",
        "indi_time_exec.append(matrix)\n",
        "\n",
        "for E in [0,1]:\n",
        "    for i in np.arange(2,len(filenames)):\n",
        "        #print(str(len(audio_features[E][1])), ' and ', str(len(audio_features[i][1])))\n",
        "        matrix = len(audio_features[E][1])*len(audio_features[i][1])/aver\n",
        "        indi_time_exec.append(matrix)\n",
        "\n",
        "print(indi_time_exec)\n",
        "# if minutes\n",
        "if (np.sum(indi_time_exec)/60 > 60):\n",
        "    print('Aprox total time of execution: ',np.sum(indi_time_exec)/60/60, 'hour(s)')\n",
        "elif (np.sum(indi_time_exec) > 60):\n",
        "    print('Aprox total time of execution: ',np.sum(indi_time_exec)/60, 'minute(s)')\n",
        "else: \n",
        "    print('Aprox total time of execution: ',np.sum(indi_time_exec), 'second(s)')\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.333785924417289, 3.9112921475446933, 3.386286490156144, 2.8612808327675943, 5.433808553971486, 4.282190540846345, 3.707399864222675, 3.1326091875990043, 5.94908350305499]\n",
            "Aprox total time of execution:  35.99773704458022 second(s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jowK5yoQSGZ8",
        "colab_type": "text"
      },
      "source": [
        "# Create DataBase Model\n",
        "---\n",
        "\n",
        "In this section, **DTW** is computed using the feature extracted from the audios and then, it save the distances into a csv in order to get the data in the next step as many times as it's required. \n",
        "\n",
        "This block is the one which requires most computation so be patient, it will take the time mentioned at the end of the last section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veXC42gWmf9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = np.size(audio_features[0], axis=0)\n",
        "print('Number of features: ', features)\n",
        "\n",
        "dB = []\n",
        "label = []\n",
        "distance = dtwDistanceND(audio_features[0], audio_features[1], features, info = True)\n",
        "dB.append(distance)\n",
        "label.append(\"E\")\n",
        "print(\"Distance between \" + labels[0] + \" and \" + labels[1] + \": \" + str(distance) + \"\")\n",
        "\n",
        "for E in [0,1]:\n",
        "    for i in np.arange(2,len(filenames)):\n",
        "        distance = dtwDistanceND(audio_features[E], audio_features[i], features, info = True)\n",
        "        print(\"Distance between \" + labels[E] + \" and \" + labels[i] + \": \" + str(distance) + \"\")\n",
        "        dB.append(distance)\n",
        "        label.append(labels[i])\n",
        "\n",
        "#print(dB)\n",
        "#print(label)\n",
        "print(\"DTW Done!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvHPm0mUq2DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"print('---------------------- TEST 3 ----------------------')\n",
        "m1_m2 = dtwDistanceND(audio_features[0], audio_features[1], 4, info = True)\n",
        "m1_m3 = dtwDistanceND(audio_features[0], audio_features[2], 4, info = True)\n",
        "m2_m3 = dtwDistanceND(audio_features[1], audio_features[2], 4, info = True)\n",
        "\n",
        "print('Distance between m1 and m2: ' + str(m1_m2))\n",
        "print('Distance between m1 and m3: ' + str(m1_m3))\n",
        "print('Distance between m2 and m3: ' + str(m2_m3))\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3_jHu9LSiLz",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Train Dataset\n",
        "---\n",
        "\n",
        "Save the DTW distance of all audios in a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyIlQmP7S5SM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "EXERCISE = 14\n",
        "PART = 4\n",
        "\n",
        "csv_filename = myDrive + \"/Data_test/ex\" + str(EXERCISE) + \"-noreb-p\" + str(PART)+\".csv\"\n",
        "features_extracted = [\"pitch\",\"centroid\", \"flatness\", \"rolloff\", \"zero-crossing\", \"mel_01\", \"mel_02\", \"mel_03\", \"mel_04\", \"mel_05\", \"mel_06\", \"mel_07\", \"mel_08\", \"mel_09\", \"mel_10\", \"mel_11\", \"mel_12\", \"mel_13\", \"mel_14\", \"mel_15\", \"label\"]\n",
        "\n",
        "with open(csv_filename, 'w') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "    for i in np.arange(0,len(dB)):\n",
        "        spamwriter.writerow([dB[i][0],dB[i][1],dB[i][2],dB[i][3],dB[i][4],dB[i][5],dB[i][6],dB[i][7],dB[i][8],dB[i][9],dB[i][10],dB[i][11],dB[i][12],dB[i][13],dB[i][14],dB[i][15],dB[i][16],dB[i][17],dB[i][18],dB[i][19], label[i]])\n",
        "        \n",
        "print(\"Model saved in \" + csv_filename)\n",
        "\n",
        "\"\"\" ------------------------- SAVE WITH DE FEATURES'S NAME--------------------------------\"\"\"\n",
        "csv_filename = myDrive + \"/Data_test/ex\" + str(EXERCISE) + \"-noreb-name-p\" + str(PART)+\".csv\"\n",
        "with open(csv_filename, 'w') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "    spamwriter.writerow(features_extracted)\n",
        "    for i in np.arange(0,len(dB)):\n",
        "        spamwriter.writerow([dB[i][0],dB[i][1],dB[i][2],dB[i][3],dB[i][4],dB[i][5],dB[i][6],dB[i][7],dB[i][8],dB[i][9],dB[i][10],dB[i][11],dB[i][12],dB[i][13],dB[i][14],dB[i][15],dB[i][16],dB[i][17],dB[i][18],dB[i][19], label[i]])\n",
        "        \n",
        "print(\"Model saved with names in \" + csv_filename)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1WZx3jfG2ek",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Test Dataset\n",
        "---\n",
        "On this step, it's done the whole process for the test dataset.\n",
        "\n",
        "At the end it's saved in a csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "241eOZHWtEIo",
        "colab": {}
      },
      "source": [
        "print(\"Starting Test\")\n",
        "# Get Test dataset\n",
        "\n",
        "\"\"\" -------------------------- FULL AUDIO ----------------------------------- \"\"\"\n",
        "# Exercise 9 Pitzzicato --------------------> DONE!!\n",
        "# test_filenames = \"0031.wav\", \"0051.wav\", \"0021.wav\", \"0041.wav\"\n",
        "\n",
        "# Exercise 14 Kreutzer 4 --------------------> DONE!!\n",
        "# test_filenames = \"0032.wav\", \"0052.wav\", \"0022.wav\", \"0042.wav\"\n",
        "\n",
        "# Exercise 18 Schradieck 1,1 --------------------> DONE!!\n",
        "# test_filenames = \"0033.wav\", \"0053.wav\", \"0023.wav\", \"0043.wav\"\n",
        "\n",
        "# Exercise 20 Sevcik 16 --------------------> ERROR!!\n",
        "# test_filenames = \"0034.wav\", \"0054.wav\", \"0024.wav\", \"0044.wav\"\n",
        "\n",
        "# Exercise 21 Shift 1st position --------------------> ERROR!!\n",
        "# test_filenames = \"0035.wav\", \"0055.wav\", \"0025.wav\", \"0045.wav\"\n",
        "\n",
        "# Exercise 23 Shift 5th position --------------------> ERROR!!\n",
        "# test_filenames = \"0036.wav\", \"0056.wav\", \"0026.wav\", \"0046.wav\"\n",
        "\n",
        "# Exercise 28 Flesch Arpeggio Excerpt --------------------> DONE!!\n",
        "# test_filenames = \"0037.wav\", \"0057.wav\", \"0027_M.wav\", \"0047.wav\"\n",
        "\n",
        "# Exercise 30 G Major scale --------------------> DONE!!\n",
        "# test_filenames = \"0038.wav\", \"0058.wav\", \"0028.wav\", \"0048.wav\"\n",
        "\n",
        "# Exercise 35 D Major scale --------------------> DONE!!\n",
        "# test_filenames = \"0039.wav\", \"0059.wav\", \"0029.wav\", \"0049.wav\"\n",
        "\n",
        "# Exercise 38 Chromatic scale --------------------> DONE!!\n",
        "# test_filenames = \"0040.wav\", \"0060.wav\", \"0030.wav\", \"0050.wav\"\n",
        "\n",
        "\"\"\" ------------------------ SEGMENTED AUDIO -------------------------------- \"\"\"\n",
        "# Exercise 14 - P1\n",
        "# test_filenames = \"0032_p1.wav\", \"0052_p1.wav\", \"0022_p1.wav\", \"0042_p1.wav\"\n",
        "\n",
        "# Exercise 14 - P2\n",
        "# test_filenames = \"0032_p2.wav\", \"0052_p2.wav\", \"0022_p2.wav\", \"0042_p2.wav\"\n",
        "\n",
        "# Exercise 14 - P3\n",
        "# test_filenames = \"0032_p3.wav\", \"0052_p3.wav\", \"0022_p3.wav\", \"0042_p3.wav\"\n",
        "\n",
        "# Exercise 14 - P4\n",
        "test_filenames = \"0032_p4.wav\", \"0052_p4.wav\", \"0022_p4.wav\", \"0042_p4.wav\"\n",
        "\n",
        "test_labels = \"E\", \"E\", \"M\", \"E\"\n",
        "\n",
        "print(\"Extracting features...\")\n",
        "audio_features = featureExtraction(test_filenames, hop_size = 10)\n",
        "\n",
        "for i in np.arange(0, len(audio_features)):\n",
        "    print(\"   Length of features from \" + test_filenames[i] + \": \" + str(len(audio_features[i][1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ynt2MeO8tDiY",
        "colab": {}
      },
      "source": [
        "# Export features of each audio (the lasts)\n",
        "\n",
        "import csv\n",
        "\n",
        "for j in np.arange(2,len(test_filenames)):\n",
        "    \n",
        "    csv_filename = myDrive + '/Features extracted/' + test_filenames[j] + '.csv'\n",
        "    features_extracted = [\"pitch\",\"centroid\", \"flatness\", \"rolloff\", \"zero-crossing\", \"mel_01\", \"mel_02\", \"mel_03\", \"mel_04\", \"mel_05\", \"mel_06\", \"mel_07\", \"mel_08\", \"mel_09\", \"mel_10\", \"mel_11\", \"mel_12\", \"mel_13\", \"mel_14\", \"mel_15\"]\n",
        "    \n",
        "    with open(csv_filename, 'w') as csvfile:\n",
        "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "        #spamwriter.writerow(features_extracted)\n",
        "        for i in np.arange(0,len(features_extracted)):\n",
        "            spamwriter.writerow(audio_features[j][i])\n",
        "\n",
        "    print(\"Features are saved in \" + csv_filename)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czKV85c8VNZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = []\n",
        "y_test = \"M\", \"E\", \"M\", \"E\"\n",
        "features = 20\n",
        "\n",
        "for E in [0,1]:\n",
        "    for i in (2,len(audio_features)-1):\n",
        "        distance = dtwDistanceND(audio_features[E], audio_features[i], features, info = True)\n",
        "        print(\"Distance between \" + test_labels[E] + \" and \" + test_labels[i] + \": \" + str(distance) + \"\")\n",
        "        X_test.append(distance)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyj5YwUYnwm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "csv_filename = myDrive + \"/Data_test/ex\" + str(EXERCISE) + \"-noreb-test-p\" + str(PART)+\".csv\"\n",
        "features_extracted = [\"pitch\",\"centroid\", \"flatness\", \"rolloff\", \"zero-crossing\", \"mel_01\", \"mel_02\", \"mel_03\", \"mel_04\", \"mel_05\", \"mel_06\", \"mel_07\", \"mel_08\", \"mel_09\", \"mel_10\", \"mel_11\", \"mel_12\", \"mel_13\", \"mel_14\", \"mel_15\", \"label\"]\n",
        "\n",
        "with open(csv_filename, 'w') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "    for i in np.arange(0,len(X_test)):\n",
        "        spamwriter.writerow([X_test[i][0],X_test[i][1],X_test[i][2],X_test[i][3],X_test[i][4],X_test[i][5],X_test[i][6],X_test[i][7],X_test[i][8],X_test[i][9],X_test[i][10],X_test[i][11],X_test[i][12],X_test[i][13],X_test[i][14],X_test[i][15],X_test[i][16],X_test[i][17],X_test[i][18],X_test[i][19], y_test[i]])\n",
        "        \n",
        "print(\"Model saved in \" + csv_filename)\n",
        "\n",
        "\n",
        "\"\"\" ------------------------- SAVE WITH DE FEATURES'S NAME--------------------------------\"\"\"\n",
        "\n",
        "csv_filename = myDrive + \"/Data_test/ex\" + str(EXERCISE) + \"-noreb-test-name-p\" + str(PART)+\".csv\"\n",
        "with open(csv_filename, 'w') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "    spamwriter.writerow(features_extracted)\n",
        "    for i in np.arange(0,len(X_test)):\n",
        "        spamwriter.writerow([X_test[i][0],X_test[i][1],X_test[i][2],X_test[i][3],X_test[i][4],X_test[i][5],X_test[i][6],X_test[i][7],X_test[i][8],X_test[i][9],X_test[i][10],X_test[i][11],X_test[i][12],X_test[i][13],X_test[i][14],X_test[i][15],X_test[i][16],X_test[i][17],X_test[i][18],X_test[i][19], y_test[i]])\n",
        "        \n",
        "print(\"Model saved with name in \" + csv_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}